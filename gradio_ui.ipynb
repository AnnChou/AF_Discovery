{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "9fd1e099",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "import gradio as gr\n",
    "import tensorflow as tf\n",
    "import cv2\n",
    "import numpy as np\n",
    "\n",
    "from PIL import Image\n",
    "from glob import glob\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import joblib\n",
    "import gradio as gr\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "dab5f844",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "ename": "OSError",
     "evalue": "No file or directory found at unet_model_path",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mOSError\u001b[0m                                   Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[10], line 3\u001b[0m\n\u001b[0;32m      1\u001b[0m unet_model_path\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mModelfile/unet_custom.hdf5\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m      2\u001b[0m os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mexists(unet_model_path)\n\u001b[1;32m----> 3\u001b[0m model \u001b[38;5;241m=\u001b[39m \u001b[43mtf\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mkeras\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmodels\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mload_model\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43munet_model_path\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\.conda\\envs\\unet-py39\\lib\\site-packages\\keras\\utils\\traceback_utils.py:70\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     67\u001b[0m     filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n\u001b[0;32m     68\u001b[0m     \u001b[38;5;66;03m# To get the full stack trace, call:\u001b[39;00m\n\u001b[0;32m     69\u001b[0m     \u001b[38;5;66;03m# `tf.debugging.disable_traceback_filtering()`\u001b[39;00m\n\u001b[1;32m---> 70\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m e\u001b[38;5;241m.\u001b[39mwith_traceback(filtered_tb) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28mNone\u001b[39m\n\u001b[0;32m     71\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[0;32m     72\u001b[0m     \u001b[38;5;28;01mdel\u001b[39;00m filtered_tb\n",
      "File \u001b[1;32m~\\.conda\\envs\\unet-py39\\lib\\site-packages\\keras\\saving\\save.py:226\u001b[0m, in \u001b[0;36mload_model\u001b[1;34m(filepath, custom_objects, compile, options)\u001b[0m\n\u001b[0;32m    224\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(filepath_str, \u001b[38;5;28mstr\u001b[39m):\n\u001b[0;32m    225\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m tf\u001b[38;5;241m.\u001b[39mio\u001b[38;5;241m.\u001b[39mgfile\u001b[38;5;241m.\u001b[39mexists(filepath_str):\n\u001b[1;32m--> 226\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mIOError\u001b[39;00m(\n\u001b[0;32m    227\u001b[0m             \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mNo file or directory found at \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfilepath_str\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    228\u001b[0m         )\n\u001b[0;32m    230\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m tf\u001b[38;5;241m.\u001b[39mio\u001b[38;5;241m.\u001b[39mgfile\u001b[38;5;241m.\u001b[39misdir(filepath_str):\n\u001b[0;32m    231\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m saved_model_load\u001b[38;5;241m.\u001b[39mload(\n\u001b[0;32m    232\u001b[0m             filepath_str, \u001b[38;5;28mcompile\u001b[39m, options\n\u001b[0;32m    233\u001b[0m         )\n",
      "\u001b[1;31mOSError\u001b[0m: No file or directory found at unet_model_path"
     ]
    }
   ],
   "source": [
    "unet_model_path=\"Modelfile/unet_custom.hdf5\"\n",
    "os.path.exists(unet_model_path)\n",
    "model = tf.keras.models.load_model(\"unet_model_path\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "925fca43",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "1f4a6c5d",
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'imgaug'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[12], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mutils_unet_a\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpy\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;241m*\u001b[39m\n",
      "File \u001b[1;32m~\\Proj\\T1_AF\\utils_unet_a.py:5\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mnumpy\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mnp\u001b[39;00m\n\u001b[0;32m      4\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mrandom\u001b[39;00m\n\u001b[1;32m----> 5\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mimgaug\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01maugmenters\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01miaa\u001b[39;00m\n\u001b[0;32m      6\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mtensorflow\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mtf\u001b[39;00m\n\u001b[0;32m      7\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mkeras\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mlosses\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m binary_crossentropy\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'imgaug'"
     ]
    }
   ],
   "source": [
    "from utils_unet_a.py import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "9f8fdc25",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Unknown loss function: bce_dice_loss. Please ensure this object is passed to the `custom_objects` argument. See https://www.tensorflow.org/guide/keras/save_and_serialize#registering_the_custom_object for details.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[11], line 7\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mnumpy\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mnp\u001b[39;00m\n\u001b[0;32m      6\u001b[0m \u001b[38;5;66;03m# Load the UNet model\u001b[39;00m\n\u001b[1;32m----> 7\u001b[0m model \u001b[38;5;241m=\u001b[39m \u001b[43mtf\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mkeras\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmodels\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mload_model\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43munet_custom.hdf5\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m      9\u001b[0m \u001b[38;5;66;03m# Define the image segmentation function\u001b[39;00m\n\u001b[0;32m     10\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21msegment_head_circumference\u001b[39m(image):\n\u001b[0;32m     11\u001b[0m     \u001b[38;5;66;03m# Preprocess the input image\u001b[39;00m\n",
      "File \u001b[1;32m~\\.conda\\envs\\unet-py39\\lib\\site-packages\\keras\\utils\\traceback_utils.py:70\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     67\u001b[0m     filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n\u001b[0;32m     68\u001b[0m     \u001b[38;5;66;03m# To get the full stack trace, call:\u001b[39;00m\n\u001b[0;32m     69\u001b[0m     \u001b[38;5;66;03m# `tf.debugging.disable_traceback_filtering()`\u001b[39;00m\n\u001b[1;32m---> 70\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m e\u001b[38;5;241m.\u001b[39mwith_traceback(filtered_tb) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28mNone\u001b[39m\n\u001b[0;32m     71\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[0;32m     72\u001b[0m     \u001b[38;5;28;01mdel\u001b[39;00m filtered_tb\n",
      "File \u001b[1;32m~\\.conda\\envs\\unet-py39\\lib\\site-packages\\keras\\utils\\generic_utils.py:769\u001b[0m, in \u001b[0;36mdeserialize_keras_object\u001b[1;34m(identifier, module_objects, custom_objects, printable_module_name)\u001b[0m\n\u001b[0;32m    767\u001b[0m     obj \u001b[38;5;241m=\u001b[39m module_objects\u001b[38;5;241m.\u001b[39mget(object_name)\n\u001b[0;32m    768\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m obj \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m--> 769\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[0;32m    770\u001b[0m             \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mUnknown \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mprintable_module_name\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mobject_name\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m. Please \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    771\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mensure this object is passed to the `custom_objects` \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    772\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124margument. See \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    773\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhttps://www.tensorflow.org/guide/keras/save_and_serialize\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    774\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m#registering_the_custom_object for details.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    775\u001b[0m         )\n\u001b[0;32m    777\u001b[0m \u001b[38;5;66;03m# Classes passed by name are instantiated with no args, functions are\u001b[39;00m\n\u001b[0;32m    778\u001b[0m \u001b[38;5;66;03m# returned as-is.\u001b[39;00m\n\u001b[0;32m    779\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m tf_inspect\u001b[38;5;241m.\u001b[39misclass(obj):\n",
      "\u001b[1;31mValueError\u001b[0m: Unknown loss function: bce_dice_loss. Please ensure this object is passed to the `custom_objects` argument. See https://www.tensorflow.org/guide/keras/save_and_serialize#registering_the_custom_object for details."
     ]
    }
   ],
   "source": [
    "import gradio as gr\n",
    "import tensorflow as tf\n",
    "import cv2\n",
    "import numpy as np\n",
    "\n",
    "# Load the UNet model\n",
    "model = tf.keras.models.load_model(\"unet_custom.hdf5\")\n",
    "\n",
    "# Define the image segmentation function\n",
    "def segment_head_circumference(image):\n",
    "    # Preprocess the input image\n",
    "    processed_image = cv2.imread(image, cv2.IMREAD_GRAYSCALE)\n",
    "    processed_image = processed_image / 255.0\n",
    "    processed_image = np.expand_dims(processed_image, axis=0)\n",
    "    processed_image = np.expand_dims(processed_image, axis=-1)\n",
    "\n",
    "    # Perform the segmentation\n",
    "    prediction = model.predict(processed_image)\n",
    "    prediction = np.squeeze(prediction)\n",
    "    binary_image = np.where(prediction > 0.5, 255, 0).astype(np.uint8)\n",
    "\n",
    "    return binary_image\n",
    "\n",
    "# Define the input and output interfaces for Gradio\n",
    "inputs = gr.inputs.Image(label=\"Ultrasound Image (PNG format)\")\n",
    "output = gr.outputs.Image(label=\"Segmented Head Circumference\")\n",
    "\n",
    "# Create the Gradio interface\n",
    "gr_interface = gr.Interface(\n",
    "    fn=segment_head_circumference,\n",
    "    inputs=inputs,\n",
    "    outputs=output,\n",
    "    title=\"Ultrasound Image Segmentation\",\n",
    "    description=\"Segment the head circumference in ultrasound images.\",\n",
    ")\n",
    "\n",
    "# Run the Gradio app on the Hugging Face Spaces platform\n",
    "gr_interface.launch()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "23f2e387",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "g_path_to = 'G:/.shortcut-targets-by-id/10wVB-YsfTmmpZyUo8jBH1cDOkVWVx5N1/T1 Project/Data/'\n",
    "os.path.exists(g_path_to)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f7fd0fdf",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "path_to = 'Data/Training-Splitted'\n",
    "os.path.exists(path_to)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "527a251b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred_img2_path_to = 'Data/predicted_images2'\n",
    "os.path.exists(pred_img2_path_to)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c347adc1",
   "metadata": {},
   "outputs": [],
   "source": [
    "files = os.listdir(path_to)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "cc5833ee",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_path_to = 'Modelfile/'\n",
    "os.path.exists(model_path_to)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "fc587cec",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rf_model_joblib_name = 'pixelCt_pixelSz_toHeadCir_rfReg.joblib'\n",
    "rf_model_joblib_file = model_path_to+rf_model_joblib_name  \n",
    "os.path.exists(rf_model_joblib_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "ec40836a",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Modelfile/pixelCt_pixelSz_toHeadCir_rfReg.joblib'"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rf_model_joblib_file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "e2d7adee",
   "metadata": {},
   "outputs": [],
   "source": [
    "#import joblib\n",
    "\n",
    "# Load the trained Random Forest model\n",
    "rf_model = joblib.load(rf_model_joblib_file)\n",
    "\n",
    "# to use rf_model.predict(input_data)   #input_data has column of feature_names = ['pixel_count','pixel size(mm)']\n",
    "feature_names = ['pixel_count','pixel size(mm)']\n",
    "\n",
    "# X = input_dffeature_names]\n",
    "# y_pred  = rf_model.predict(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7fb931e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "88e5cb0b",
   "metadata": {},
   "outputs": [],
   "source": [
    "##### function get_pixe_count get_pixel_count(img_data_path, filename) ###  duplicate code from above.\n",
    "def get_pixel_count(img_data_path, filename):\n",
    "    file_path = os.path.join(img_data_path, filename)\n",
    "    if os.path.exists(file_path):\n",
    "        label = Image.open(file_path)\n",
    "        label = np.array(label)\n",
    "        label = tf.convert_to_tensor(label)\n",
    "        label = tf.cast(label, tf.float32) / 255.0\n",
    "        label = tf.cast(label, tf.int32)\n",
    "        pixel_count = np.sum(label)\n",
    "    else:\n",
    "        print(\"No such file: \" + filename)\n",
    "        pixel_count = np.nan\n",
    "\n",
    "    return pixel_count\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "273eec06",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\annch\\.conda\\envs\\unet-py39\\lib\\site-packages\\gradio\\inputs.py:257: UserWarning: Usage of gradio.inputs is deprecated, and will not be supported in the future, please import your component from gradio.components\n",
      "  warnings.warn(\n",
      "C:\\Users\\annch\\.conda\\envs\\unet-py39\\lib\\site-packages\\gradio\\deprecation.py:40: UserWarning: `optional` parameter is deprecated, and it has no effect\n",
      "  warnings.warn(value)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running on local URL:  http://127.0.0.1:7862\n",
      "\n",
      "To create a public link, set `share=True` in `launch()`.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div><iframe src=\"http://127.0.0.1:7862/\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": []
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "### get_pixel_count_gradio demo ###\n",
    "import numpy as np\n",
    "import gradio as gr\n",
    "\n",
    "def get_pixel_count_gradio(input_img):\n",
    "    label = np.array(input_img)\n",
    "    label = tf.convert_to_tensor(label)\n",
    "    label = tf.cast(label, tf.float32) / 255.0\n",
    "    label = tf.cast(label, tf.int32)\n",
    "    pixel_count = np.sum(label)\n",
    "    print(pixel_count)\n",
    "    return pixel_count\n",
    "\n",
    "demo = gr.Interface(\n",
    "    fn=get_pixel_count_gradio,\n",
    "    inputs=gr.inputs.Image(shape=(800, 540)),\n",
    "    outputs=\"number\"\n",
    ")\n",
    "\n",
    "#demo.launch(share=True)\n",
    "demo.launch()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "b4a15a30",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\annch\\.conda\\envs\\unet-py39\\lib\\site-packages\\gradio\\inputs.py:257: UserWarning: Usage of gradio.inputs is deprecated, and will not be supported in the future, please import your component from gradio.components\n",
      "  warnings.warn(\n",
      "C:\\Users\\annch\\.conda\\envs\\unet-py39\\lib\\site-packages\\gradio\\deprecation.py:40: UserWarning: `optional` parameter is deprecated, and it has no effect\n",
      "  warnings.warn(value)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running on local URL:  http://127.0.0.1:7863\n",
      "\n",
      "To create a public link, set `share=True` in `launch()`.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div><iframe src=\"http://127.0.0.1:7863/\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\annch\\.conda\\envs\\unet-py39\\lib\\site-packages\\gradio\\inputs.py:257: UserWarning: Usage of gradio.inputs is deprecated, and will not be supported in the future, please import your component from gradio.components\n",
      "  warnings.warn(\n",
      "C:\\Users\\annch\\.conda\\envs\\unet-py39\\lib\\site-packages\\gradio\\deprecation.py:40: UserWarning: `optional` parameter is deprecated, and it has no effect\n",
      "  warnings.warn(value)\n",
      "C:\\Users\\annch\\.conda\\envs\\unet-py39\\lib\\site-packages\\gradio\\inputs.py:59: UserWarning: Usage of gradio.inputs is deprecated, and will not be supported in the future, please import your component from gradio.components\n",
      "  warnings.warn(\n",
      "C:\\Users\\annch\\.conda\\envs\\unet-py39\\lib\\site-packages\\gradio\\outputs.py:22: UserWarning: Usage of gradio.outputs is deprecated, and will not be supported in the future, please import your components from gradio.components\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running on local URL:  http://127.0.0.1:7864\n",
      "\n",
      "To create a public link, set `share=True` in `launch()`.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div><iframe src=\"http://127.0.0.1:7864/\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": []
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "import gradio as gr\n",
    "import joblib\n",
    "\n",
    "# Load the RF model\n",
    "#rf_model = joblib.load(\"rf_model_joblib_file\")\n",
    "\n",
    "### get_pixel_count_gradio demo ###\n",
    "def get_pixel_count_gradio(input_img):\n",
    "    label = np.array(input_img)\n",
    "    pixel_count = np.sum(label)\n",
    "    print(pixel_count)\n",
    "    return pixel_count\n",
    "\n",
    "demo = gr.Interface(\n",
    "    fn=get_pixel_count_gradio,\n",
    "    inputs=gr.inputs.Image(shape=(800, 540)),\n",
    "    outputs=\"number\"\n",
    ")\n",
    "\n",
    "demo.launch()\n",
    "\n",
    "def predict_head_circumference(input_img, pixel_size):\n",
    "    # Use the pixel size and other features to make a prediction\n",
    "    feature_names = ['pixel_count', 'pixel size(mm)']  # Add other relevant features here\n",
    "    pixel_count = get_pixel_count_gradio(input_img)\n",
    "    \n",
    "    prediction = rf_model.predict([[pixel_count, pixel_size]])[0]\n",
    "    print(prediction)\n",
    "    \n",
    "    return prediction\n",
    "\n",
    "inputs = [\n",
    "    gr.inputs.Image(label=\"Image\"),\n",
    "    gr.inputs.Number(label=\"Pixel Size (mm)\")\n",
    "]\n",
    "\n",
    "output = gr.outputs.Textbox(label=\"Head Circumference (mm)\")\n",
    "\n",
    "gr_interface = gr.Interface(\n",
    "    fn=predict_head_circumference,\n",
    "    inputs=inputs,\n",
    "    outputs=output,\n",
    "    title=\"Head Circumference Predictor\",\n",
    "    description=\"Predicts the head circumference based on an image and pixel size.\",\n",
    ")\n",
    "\n",
    "gr_interface.launch()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "8dbfb01b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\annch\\.conda\\envs\\unet-py39\\lib\\site-packages\\gradio\\inputs.py:257: UserWarning: Usage of gradio.inputs is deprecated, and will not be supported in the future, please import your component from gradio.components\n",
      "  warnings.warn(\n",
      "C:\\Users\\annch\\.conda\\envs\\unet-py39\\lib\\site-packages\\gradio\\deprecation.py:40: UserWarning: `optional` parameter is deprecated, and it has no effect\n",
      "  warnings.warn(value)\n",
      "C:\\Users\\annch\\.conda\\envs\\unet-py39\\lib\\site-packages\\gradio\\inputs.py:59: UserWarning: Usage of gradio.inputs is deprecated, and will not be supported in the future, please import your component from gradio.components\n",
      "  warnings.warn(\n",
      "C:\\Users\\annch\\.conda\\envs\\unet-py39\\lib\\site-packages\\gradio\\outputs.py:22: UserWarning: Usage of gradio.outputs is deprecated, and will not be supported in the future, please import your components from gradio.components\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running on local URL:  http://127.0.0.1:7865\n",
      "\n",
      "To create a public link, set `share=True` in `launch()`.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div><iframe src=\"http://127.0.0.1:7865/\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": []
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "#import gradio as gr\n",
    "#import pandas as pd\n",
    "#import joblib\n",
    "#import cv2\n",
    "\n",
    "# Load the RF model\n",
    "rf_model = joblib.load(rf_model_joblib_file)\n",
    "\n",
    "# Load the CSV file with pixel size data\n",
    "#csv_file_path = 'pixel_size_data.csv'\n",
    "#pixel_size_data = pd.read_csv(csv_file_path)\n",
    "\n",
    "def predict_head_circumference(input_img, pixel_size):\n",
    "    # Process the image (e.g., resize, normalize, etc.)\n",
    "    #processed_image = preprocess_image(image)  #image already in binary form\n",
    "    \n",
    "    # Use the pixel size and other features to make a prediction\n",
    "    feature_names = ['pixel_count','pixel size(mm)']  # Add other relevant features here\n",
    "    pixel_count = get_pixel_count_gradio(input_img)\n",
    "    pixel_size = pixel_size\n",
    "    \n",
    "    prediction = rf_model.predict([pixel_count,pixel_size])[0]\n",
    "    print(prediction)\n",
    "    \n",
    "    return prediction\n",
    "\n",
    "#def preprocess_image(image):\n",
    "#    # Preprocess the image (e.g., resize, normalize, etc.)\n",
    "#    # Modify this function based on your specific image preprocessing requirements\n",
    "#    processed_image = cv2.resize(image, (224, 224))\n",
    "#    processed_image = processed_image / 255.0  # Normalize pixel values\n",
    "    \n",
    "#    return processed_image\n",
    "\n",
    "# Define the input and output interfaces for Gradio\n",
    "inputs = [\n",
    "    gr.inputs.Image(label=\"Image\"),\n",
    "    gr.inputs.Number(label=\"Pixel Size (mm)\")\n",
    "]\n",
    "\n",
    "output = gr.outputs.Textbox(label=\"Head Circumference (mm)\")\n",
    "\n",
    "# Create the Gradio interface\n",
    "gr_interface = gr.Interface(\n",
    "    fn=predict_head_circumference,\n",
    "    inputs=inputs,\n",
    "    outputs=output,\n",
    "    title=\"Head Circumference Predictor\",\n",
    "    description=\"Predicts the head circumference based on an image and pixel size.\",\n",
    ")\n",
    "\n",
    "# Run the Gradio app\n",
    "gr_interface.launch()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "06db1ceb",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\annch\\.conda\\envs\\unet-py39\\lib\\site-packages\\gradio\\outputs.py:22: UserWarning: Usage of gradio.outputs is deprecated, and will not be supported in the future, please import your components from gradio.components\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running on local URL:  http://127.0.0.1:7866\n",
      "\n",
      "To create a public link, set `share=True` in `launch()`.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div><iframe src=\"http://127.0.0.1:7866/\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": []
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import gradio as gr\n",
    "\n",
    "def greet(name):\n",
    "    return \"Hello \" + name + \"!\"\n",
    "\n",
    "demo = gr.Interface(\n",
    "    fn=greet,\n",
    "    inputs=gr.Textbox(lines=2, placeholder=\"Name Here...\"),\n",
    "    #outputs=\"text\",\n",
    "    outputs=gr.outputs.Textbox(label=\"Prediction\")\n",
    ")\n",
    "demo.launch()\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "667961cb",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "fded7624",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running on local URL:  http://127.0.0.1:7867\n",
      "\n",
      "To create a public link, set `share=True` in `launch()`.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div><iframe src=\"http://127.0.0.1:7867/\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": []
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "import gradio as gr\n",
    "\n",
    "def sepia(input_img):\n",
    "    sepia_filter = np.array([\n",
    "        [0.393, 0.769, 0.189], \n",
    "        [0.349, 0.686, 0.168], \n",
    "        [0.272, 0.534, 0.131]\n",
    "    ])\n",
    "    sepia_img = input_img.dot(sepia_filter.T)\n",
    "    sepia_img /= sepia_img.max()\n",
    "    return sepia_img\n",
    "\n",
    "demo = gr.Interface(sepia, gr.Image(shape=(200, 200)), \"image\")\n",
    "demo.launch()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49f23fa2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "e6a9e86b",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'image' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[16], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;66;03m# Get the input shape\u001b[39;00m\n\u001b[1;32m----> 2\u001b[0m input_shape \u001b[38;5;241m=\u001b[39m \u001b[43mimage\u001b[49m\u001b[38;5;241m.\u001b[39msize\n\u001b[0;32m      4\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mInput shape:\u001b[39m\u001b[38;5;124m\"\u001b[39m, input_shape)\n",
      "\u001b[1;31mNameError\u001b[0m: name 'image' is not defined"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3603150\n",
      "137.53759999999988\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\annch\\.conda\\envs\\unet-py39\\lib\\site-packages\\sklearn\\base.py:439: UserWarning: X does not have valid feature names, but RandomForestRegressor was fitted with feature names\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# Get the input shape\n",
    "input_shape = image.size\n",
    "\n",
    "print(\"Input shape:\", input_shape)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
